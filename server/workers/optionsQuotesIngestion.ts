/**
 * Options Quotes Ingestion Worker
 * Downloads bid/ask quotes from Massive.com S3 flat files and stores in database
 *
 * Data Source: s3://flatfiles/us_options_opra/quotes_v1/
 * File Format: CSV.GZ (gzipped CSV)
 *
 * Fields:
 * - ticker: Option ticker (e.g., "SPY250117C00500000")
 * - bid_price, ask_price: Bid and ask prices
 * - bid_size, ask_size: Size in round lots
 * - bid_exchange, ask_exchange: Exchange identifiers
 * - sip_timestamp: Nanosecond Unix timestamp
 * - sequence_number: Daily sequence number
 *
 * Usage:
 *   pnpm quotes:ingest                    # Last 7 days
 *   pnpm quotes:ingest --days=30          # Last 30 days
 *   pnpm quotes:ingest --underlying=SPY   # Single underlying
 */

import { config } from "dotenv";
config({ path: ".env.local" });

import { S3Client, GetObjectCommand } from "@aws-sdk/client-s3";
import { createClient } from "@supabase/supabase-js";
import { createReadStream, createWriteStream, existsSync, unlinkSync } from "fs";
import { createGunzip } from "zlib";
import { pipeline } from "stream/promises";
import { parse } from "csv-parse";
import * as path from "path";
import * as os from "os";

// ============================================================================
// Configuration
// ============================================================================

const S3_ENDPOINT = "https://files.massive.com";
const S3_ACCESS_KEY = process.env.MASSIVE_AWS_ACCESS_KEY || "";
const S3_SECRET_KEY = process.env.MASSIVE_AWS_SECRET_KEY || "";
const S3_BUCKET = "flatfiles";
const S3_QUOTES_PATH = "us_options_opra/quotes_v1";

const SUPABASE_URL = process.env.SUPABASE_URL || process.env.VITE_SUPABASE_URL!;
const SUPABASE_SERVICE_ROLE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY!;

// Singleton Supabase client
let supabaseClient: ReturnType<typeof createClient> | null = null;

function getSupabaseClient() {
  if (!supabaseClient && SUPABASE_URL && SUPABASE_SERVICE_ROLE_KEY) {
    supabaseClient = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);
  }
  return supabaseClient!;
}

// Validate environment
if (!S3_ACCESS_KEY || !S3_SECRET_KEY) {
  console.error("‚ùå Missing MASSIVE_AWS_ACCESS_KEY or MASSIVE_AWS_SECRET_KEY");
  process.exit(1);
}

if (!SUPABASE_URL || !SUPABASE_SERVICE_ROLE_KEY) {
  console.error("‚ùå Missing Supabase environment variables");
  process.exit(1);
}

// Initialize clients
const s3Client = new S3Client({
  endpoint: S3_ENDPOINT,
  region: "us-east-1",
  credentials: {
    accessKeyId: S3_ACCESS_KEY,
    secretAccessKey: S3_SECRET_KEY,
  },
  forcePathStyle: true,
});

const supabase = getSupabaseClient();

// CLI arguments
const args = process.argv.slice(2);
const daysArg = args.find((a) => a.startsWith("--days="))?.split("=")[1];
const underlyingArg = args.find((a) => a.startsWith("--underlying="))?.split("=")[1];
const DAYS_TO_INGEST = daysArg ? parseInt(daysArg) : 7;

// Underlyings to track (matches backtest watchlist)
const TARGET_UNDERLYINGS = underlyingArg
  ? [underlyingArg.toUpperCase()]
  : ["SPY", "SPX", "NDX", "QQQ", "TSLA", "AMD", "MSFT", "SOFI"];

// ============================================================================
// S3 Download Functions
// ============================================================================

/**
 * Generate S3 key for quotes file
 * Format: us_options_opra/quotes_v1/{YYYY}/{MM}/{YYYY-MM-DD}.csv.gz
 */
function getQuotesS3Key(date: Date): string {
  const year = date.getFullYear();
  const month = String(date.getMonth() + 1).padStart(2, "0");
  const day = String(date.getDate()).padStart(2, "0");
  const dateStr = `${year}-${month}-${day}`;
  return `${S3_QUOTES_PATH}/${year}/${month}/${dateStr}.csv.gz`;
}

/**
 * Download and decompress quotes file from S3
 */
async function downloadQuotesFile(date: Date): Promise<string | null> {
  const s3Key = getQuotesS3Key(date);
  const tempDir = os.tmpdir();
  const dateStr = date.toISOString().split("T")[0];
  const gzipPath = path.join(tempDir, `options-quotes-${dateStr}.csv.gz`);
  const csvPath = gzipPath.replace(".gz", "");

  // Check cache
  if (existsSync(csvPath)) {
    console.log(`  üìÅ Using cached: ${csvPath}`);
    return csvPath;
  }

  console.log(`  üì• Downloading ${s3Key}...`);

  try {
    const command = new GetObjectCommand({
      Bucket: S3_BUCKET,
      Key: s3Key,
    });

    const response = await s3Client.send(command);

    if (!response.Body) {
      console.log(`  ‚ö†Ô∏è No data for ${dateStr}`);
      return null;
    }

    // Save gzipped file
    const writeStream = createWriteStream(gzipPath);
    // @ts-expect-error - AWS SDK stream typing
    await pipeline(response.Body, writeStream);

    // Decompress
    const readStream = createReadStream(gzipPath);
    const gunzip = createGunzip();
    const outputStream = createWriteStream(csvPath);
    await pipeline(readStream, gunzip, outputStream);

    // Cleanup
    unlinkSync(gzipPath);

    console.log(`  ‚úÖ Downloaded and decompressed`);
    return csvPath;
  } catch (error: any) {
    if (error.name === "NoSuchKey") {
      console.log(`  ‚ö†Ô∏è No file for ${dateStr} (weekend/holiday?)`);
    } else {
      console.error(`  ‚ùå Download failed: ${error.message}`);
    }
    return null;
  }
}

// ============================================================================
// CSV Parsing Functions
// ============================================================================

/**
 * Extract underlying symbol from option ticker
 * Format: SPY250117C00500000 -> SPY
 * Format: SPXW250117C05800000 -> SPX
 */
function extractUnderlying(optionTicker: string): string {
  // Remove O: prefix if present
  const ticker = optionTicker.replace(/^O:/, "");

  // Match letters at start (underlying) followed by date
  const match = ticker.match(/^([A-Z]+)\d/);
  if (!match) return "";

  let underlying = match[1];

  // Handle special cases
  if (underlying === "SPXW") underlying = "SPX";
  if (underlying === "NDXW") underlying = "NDX";

  return underlying;
}

/**
 * Convert nanosecond timestamp to millisecond timestamp at minute boundary
 */
function nanosToMinuteMs(nanosTimestamp: string): number {
  // Convert nanoseconds to milliseconds, truncate to minute
  const ms = Math.floor(parseInt(nanosTimestamp) / 1_000_000);
  return Math.floor(ms / 60_000) * 60_000;
}

/**
 * Quote record from CSV
 */
interface RawQuote {
  ticker: string;
  bid_price: number;
  ask_price: number;
  bid_size: number;
  ask_size: number;
  bid_exchange: number;
  ask_exchange: number;
  sip_timestamp: string;
}

/**
 * Aggregated minute quote
 */
interface MinuteQuote {
  underlying: string;
  option_ticker: string;
  timestamp: number;
  bid_price: number;
  ask_price: number;
  bid_size: number;
  ask_size: number;
  bid_exchange: number;
  ask_exchange: number;
}

/**
 * Parse CSV and aggregate to minute-level quotes
 * Only keeps quotes for target underlyings
 */
async function parseAndAggregateQuotes(csvPath: string): Promise<MinuteQuote[]> {
  console.log(`  üîç Parsing quotes...`);

  // Map to aggregate quotes by ticker+minute
  const minuteMap = new Map<string, MinuteQuote>();
  let totalRows = 0;
  let matchedRows = 0;

  return new Promise((resolve, reject) => {
    const parser = parse({
      columns: true,
      skip_empty_lines: true,
      cast: (value, context) => {
        // Cast numeric columns
        if (["bid_price", "ask_price"].includes(context.column as string)) {
          return parseFloat(value) || 0;
        }
        if (
          ["bid_size", "ask_size", "bid_exchange", "ask_exchange"].includes(
            context.column as string
          )
        ) {
          return parseInt(value) || 0;
        }
        return value;
      },
    });

    const readStream = createReadStream(csvPath);
    readStream.pipe(parser);

    parser.on("data", (row: RawQuote) => {
      totalRows++;

      // Extract underlying
      const underlying = extractUnderlying(row.ticker);

      // Filter to target underlyings only
      if (!TARGET_UNDERLYINGS.includes(underlying)) {
        return;
      }

      matchedRows++;

      // Skip invalid quotes
      if (row.bid_price <= 0 || row.ask_price <= 0) {
        return;
      }

      // Aggregate to minute
      const minuteTs = nanosToMinuteMs(row.sip_timestamp);
      const key = `${row.ticker}:${minuteTs}`;

      // Keep the latest quote per minute (overwrites earlier ones)
      minuteMap.set(key, {
        underlying,
        option_ticker: row.ticker,
        timestamp: minuteTs,
        bid_price: row.bid_price,
        ask_price: row.ask_price,
        bid_size: row.bid_size,
        ask_size: row.ask_size,
        bid_exchange: row.bid_exchange,
        ask_exchange: row.ask_exchange,
      });

      // Progress log every 1M rows
      if (totalRows % 1_000_000 === 0) {
        console.log(
          `    Processed ${(totalRows / 1_000_000).toFixed(1)}M rows, ${matchedRows} matched, ${minuteMap.size} unique minutes`
        );
      }
    });

    parser.on("error", reject);

    parser.on("end", () => {
      console.log(
        `  üìä Parsed ${totalRows.toLocaleString()} rows, ${matchedRows.toLocaleString()} matched, ${minuteMap.size.toLocaleString()} unique quotes`
      );
      resolve(Array.from(minuteMap.values()));
    });
  });
}

// ============================================================================
// Database Functions
// ============================================================================

/**
 * Upsert quotes to database in batches
 */
async function upsertQuotes(quotes: MinuteQuote[]): Promise<number> {
  if (quotes.length === 0) return 0;

  console.log(`  üíæ Upserting ${quotes.length.toLocaleString()} quotes...`);

  const BATCH_SIZE = 1000;
  let inserted = 0;

  for (let i = 0; i < quotes.length; i += BATCH_SIZE) {
    const batch = quotes.slice(i, i + BATCH_SIZE);

    const { error } = await supabase
      .from("options_quotes")
      .upsert(batch as any, { onConflict: "underlying,option_ticker,timestamp" });

    if (error) {
      console.error(`  ‚ùå Upsert error: ${error.message}`);
      // Continue with next batch
    } else {
      inserted += batch.length;
    }

    // Progress every 10 batches
    if ((i / BATCH_SIZE) % 10 === 0 && i > 0) {
      console.log(`    Upserted ${inserted.toLocaleString()}/${quotes.length.toLocaleString()}`);
    }
  }

  return inserted;
}

/**
 * Get stats for a date range
 */
async function getQuoteStats(): Promise<void> {
  const { data, error } = await supabase
    .from("options_quotes")
    .select("underlying, count(*)")
    .order("underlying");

  if (error) {
    console.error("Stats error:", error.message);
    return;
  }

  console.log("\nüìà Quote Stats by Underlying:");
  // Note: This simplified query won't work directly, but gives the idea
  console.log("  (Run SQL query for detailed stats)");
}

// ============================================================================
// Main Worker
// ============================================================================

async function main(): Promise<void> {
  console.log("=".repeat(60));
  console.log("üìä OPTIONS QUOTES INGESTION WORKER");
  console.log("=".repeat(60));
  console.log(`Days to ingest: ${DAYS_TO_INGEST}`);
  console.log(`Target underlyings: ${TARGET_UNDERLYINGS.join(", ")}`);
  console.log("");

  const endDate = new Date();
  const startDate = new Date(endDate.getTime() - DAYS_TO_INGEST * 24 * 60 * 60 * 1000);

  let totalQuotes = 0;
  let successDays = 0;

  // Process each day
  for (let d = new Date(startDate); d <= endDate; d.setDate(d.getDate() + 1)) {
    const dateStr = d.toISOString().split("T")[0];
    console.log(`\nüìÖ Processing ${dateStr}...`);

    // Skip weekends
    const dayOfWeek = d.getDay();
    if (dayOfWeek === 0 || dayOfWeek === 6) {
      console.log("  ‚è≠Ô∏è Skipping weekend");
      continue;
    }

    // Download file
    const csvPath = await downloadQuotesFile(new Date(d));
    if (!csvPath) continue;

    // Parse and aggregate
    const quotes = await parseAndAggregateQuotes(csvPath);
    if (quotes.length === 0) {
      console.log("  ‚ö†Ô∏è No matching quotes found");
      continue;
    }

    // Upsert to database
    const inserted = await upsertQuotes(quotes);
    totalQuotes += inserted;
    successDays++;

    console.log(`  ‚úÖ Inserted ${inserted.toLocaleString()} quotes`);
  }

  console.log("\n" + "=".repeat(60));
  console.log("‚úÖ INGESTION COMPLETE");
  console.log("=".repeat(60));
  console.log(`Days processed: ${successDays}`);
  console.log(`Total quotes: ${totalQuotes.toLocaleString()}`);

  // Show stats
  await getQuoteStats();
}

// Run
main().catch((err) => {
  console.error("‚ùå Fatal error:", err);
  process.exit(1);
});
